{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "titanic.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LUiwtshlZU1",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "ColaboratoryでKaggleを始める\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0E349WbxCMaG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HviuQI62_pn3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from googleapiclient.discovery import build\n",
        "import io, os\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "from google.colab import auth\n",
        "\n",
        "auth.authenticate_user()\n",
        "\n",
        "drive_service = build('drive', 'v3')\n",
        "results = drive_service.files().list(\n",
        "        q=\"name = 'kaggle.json'\", fields=\"files(id)\").execute()\n",
        "kaggle_api_key = results.get('files', [])\n",
        "\n",
        "filename = \"/root/.kaggle/kaggle.json\"\n",
        "os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
        "\n",
        "request = drive_service.files().get_media(fileId=kaggle_api_key[0]['id'])\n",
        "fh = io.FileIO(filename, 'wb')\n",
        "downloader = MediaIoBaseDownload(fh, request)\n",
        "done = False\n",
        "while done is False:\n",
        "    status, done = downloader.next_chunk()\n",
        "    print(\"Download %d%%.\" % int(status.progress() * 100))\n",
        "os.chmod(filename, 600)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHx9TPO9QZZa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kaggle competitions list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVYpfQJDBHVg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kaggle competitions download -c titanic"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhy3XjpYPkna",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import time\n",
        "\n",
        "def parse(df):\n",
        "    # Nan を -1 に置換\n",
        "    df[\"Age\"] = df[\"Age\"].fillna(-1)\n",
        "    df[\"Embarked\"] = df[\"Embarked\"].fillna(-1)\n",
        "    # 文字列を数値に変換\n",
        "    df[\"Sex\"][df[\"Sex\"] == \"male\"] = 0\n",
        "    df[\"Sex\"][df[\"Sex\"] == \"female\"] = 1\n",
        "    df[\"Embarked\"][df[\"Embarked\"] == \"S\" ] = 0\n",
        "    df[\"Embarked\"][df[\"Embarked\"] == \"C\" ] = 1\n",
        "    df[\"Embarked\"][df[\"Embarked\"] == \"Q\"] = 2\n",
        "    return df\n",
        "\n",
        "def split_val(x,y,rate,seed=None):\n",
        "    # x,y の rate[%] をランダム分割\n",
        "    N = x.shape[0]\n",
        "    val_num = int(N*rate)\n",
        "    if seed is not None:\n",
        "        np.random.seed(seed)\n",
        "    perm = np.random.permutation(N)\n",
        "    ti = perm[:-val_num]\n",
        "    vi = perm[-val_num:]\n",
        "    return x[ti],y[ti],x[vi],y[vi]\n",
        "\n",
        "def load_data():\n",
        "    train_csv = pd.read_csv('train.csv')\n",
        "    train_csv = parse(train_csv)\n",
        "    train_x = train_csv[['Pclass', 'Sex', 'Fare','SibSp', 'Parch', 'Age', 'Embarked']].values\n",
        "    train_y = train_csv['Survived'].values\n",
        "    return split_val(train_x,train_y,0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9boYd3GPksY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(input_placeholder,u_dim,layer_num,y_dim,training):\n",
        "    h = input_placeholder\n",
        "    for i in range(layer_num):\n",
        "        h = tf.layers.dense(inputs=h, units=u_dim,activation=tf.nn.relu)\n",
        "        h = tf.layers.batch_normalization(h,training=training)  \n",
        "    h = tf.layers.dense(inputs=h, units=y_dim)\n",
        "    return h\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "te8-rT38PkvW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(0)\n",
        "tf.reset_default_graph()\n",
        "y_dim     = 2\n",
        "# hyperparameters\n",
        "u_dim     = 100\n",
        "layer_num = 2\n",
        "epoch     = 1000\n",
        "log_freq  = 100\n",
        "batchsize = 200\n",
        "lr        = 0.001\n",
        "\n",
        "# data load\n",
        "train_x,train_y,val_x,val_y = load_data()\n",
        "N  = train_y.shape[0]\n",
        "Nv = val_y.shape[0]\n",
        "print('train num: {}, val num: {}'.format(N,Nv))\n",
        "\n",
        "# calculation graph\n",
        "x = tf.placeholder(tf.float32, [None, train_x.shape[1]],\"input\")\n",
        "y = tf.placeholder(tf.int32, [None])\n",
        "\n",
        "with tf.variable_scope(\"model\"):\n",
        "  train_z = create_model(x,u_dim,layer_num,y_dim,training=True)\n",
        "with tf.variable_scope(\"model\", reuse=True):\n",
        "  z       = create_model(x,u_dim,layer_num,y_dim,training=False)\n",
        "\n",
        "cross_entropy = tf.losses.sparse_softmax_cross_entropy(labels=y, logits=train_z)\n",
        "\n",
        "extra_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
        "with tf.control_dependencies(extra_ops):\n",
        "  train_step = tf.train.AdamOptimizer(lr).minimize(cross_entropy)\n",
        "\n",
        "pred_y = tf.cast(tf.argmax(z, 1), tf.int32)\n",
        "accuracy = tf.reduce_mean(tf.cast(tf.equal(pred_y, y), tf.float32))\n",
        "\n",
        "# main loop\n",
        "sess = tf.InteractiveSession()\n",
        "tf.global_variables_initializer().run()\n",
        "T = time.time() \n",
        "for ep in range(1,epoch+1) :\n",
        "  perm=np.random.permutation(N)\n",
        "  for i in range(0,N,batchsize):\n",
        "    batch_xs=train_x[perm[i:i+batchsize]]\n",
        "    batch_ys=train_y[perm[i:i+batchsize]]\n",
        "    sess.run(train_step, feed_dict={x: batch_xs, y: batch_ys})\n",
        "  # monitor\n",
        "  if ep%log_freq ==0 :      \n",
        "    train_loss, train_acc = sess.run([cross_entropy, accuracy], feed_dict={x: train_x, y: train_y})\n",
        "    val_loss, val_acc     = sess.run([cross_entropy, accuracy], feed_dict={x: val_x, y: val_y})\n",
        "    epochT = time.time()-T\n",
        "    print('Epoch: %d, Time :%.4f (s), train_loss: %f,  train_acc: %f, val_loss: %f,  val_acc: %f' % (ep, epochT, train_loss, train_acc, val_loss, val_acc))\n",
        "    T = time.time()\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUakTdGdPkzo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data\n",
        "test_csv = pd.read_csv('test.csv')\n",
        "test_csv = parse(test_csv)\n",
        "test_x = test_csv[['Pclass', 'Sex', 'Fare','SibSp', 'Parch', 'Age', 'Embarked']].values\n",
        "# predict\n",
        "prediction = sess.run(pred_y, feed_dict={x: test_x})\n",
        "# parse\n",
        "PassengerId = np.array(test_csv[\"PassengerId\"]).astype(int)\n",
        "my_solution = pd.DataFrame(prediction, PassengerId, columns = [\"Survived\"])\n",
        "# save\n",
        "my_solution.to_csv(\"result.csv\", index_label = [\"PassengerId\"])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFLRLdY1hYia",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cat result.csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrsT5Iq4hYsI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kaggle competitions submit -c titanic -f result.csv -m 'first submit'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYlgQ-hAhYyH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}